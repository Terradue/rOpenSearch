# Geohazards 

## The European Space Agency Virtual Archive

Virtual Archives are online archives that provide an easy access to EO data by coupling high bandwidth, large storage space and software. The Virtual Archive 4 provides a Cloud based service for storing and providing access to ESA Synthetic Aperture Radar (SAR) data.

This virtual archive represents ESA contribution to the supersites initiative. This huge amount of SAR data (today nearly ninty thousand products are hosted on Virtual Archive 4) is accessible to science communities dealing with interferometry, landslide and change detection

## Use rOpenSearch to query the Virtual Archive Envisat ASAR Image Mode Level 0 data

This example will return the 100 first dataset spanning time interval 2010-01-01 to 2010-01-31

#### Load the required packages with:

```{r warning=FALSE, error=FALSE, message=FALSE, results='hide'}
# load the libraries
library(devtools)
library(rgdal)
library(rgeos)
library(XML)
library(rOpenSearch)
```

#### Define the OpenSearch description URL

```{r}
osd.url <- "http://eo-virtual-archive4.esa.int/search/ASA_IM__0P/description"
```
* Get the list of OpenSearch response types:

```{r}
GetOSResponseFormats(osd.url)
```

* Set the OpenSearch response type to use:

```{r}
response.type <- "application/rdf+xml"
```

* get the queryables dataframe from the OpenSearch description URL

```{r}
df.params <- GetOSQueryables(osd.url, response.type)
```

#### Assign values to the queryables

```{r}
df.params$value[df.params$type == "count"] <- 100 
df.params$value[df.params$type == "time:start"] <- "2010-01-01"
df.params$value[df.params$type == "time:end"] <- "2010-01-31"
```

#### Submit the query

```{r  warning=FALSE}
res <- Query(osd.url, response.type, df.params)
```

#### Get the dataset

```{r warning=FALSE}
dataset <- xmlToDataFrame(nodes = getNodeSet(xmlParse(res), 
  "//dclite4g:DataSet"), stringsAsFactors = FALSE)
```

#### Create a SpatialPolygonsDataFrame with the dataset

```{r}
poly.sp <- SpatialPolygonsDataFrame(readWKT(data.frame(dataset$spatial)[1,]), dataset[1,])

# iterate through the remaining dataset
for (n in 2:nrow(dataset)) {
  poly.sp <- rbind(poly.sp,
    SpatialPolygonsDataFrame(readWKT(data.frame(dataset$spatial)[n,],id=n), dataset[n,]))
}
```

#### write the geojson file

```{r}
writeOGR(poly.sp, 'example1.geojson','dataMap', driver='GeoJSON')
```

The GeoJSON file can be see here: https://github.com/Terradue/rOpenSearch/blob/master/src/main/R/examples/example1.geojson


```{r results="asis"}

library(rMaps)
library(knitr)
map <- Leaflet$new()
map$setView(c(51.505, -0.09), zoom = 13)
map$tileLayer(provider = "Stamen.Watercolor")
map$marker(c(51.5, -0.09), bindPopup = "Hi. I am a popup")
map
```


### leaflet

```{r results="asis"}
library(rCharts)
json <- read_file("example1.geojson")
regions=RJSONIO::fromJSON(json)

lmap <- Leaflet$new()
lmap$tileLayer(provide='Stamen.TonerLite')
lmap$setView(c(-37, 145), zoom = 6)
lmap$geoJson(regions)
lmap$print()
```
